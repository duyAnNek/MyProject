{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1zv000ZGL5cs4wvI3KwcvQuZ9gSPfgkLL","authorship_tag":"ABX9TyMndu1iHQZc+dN+eWt2Hs/T"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3MEbixyspnwK","executionInfo":{"status":"ok","timestamp":1747625786312,"user_tz":-420,"elapsed":12554,"user":{"displayName":"An Nguyễn","userId":"14264574941995497895"}},"outputId":"fdbb3e46-4e66-4b3f-80f2-effe2ac71376"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["!pip install -q gradio\n","!pip install -q efficientnet-pytorch\n","\n","import gradio as gr\n","import torch\n","import torch.nn as nn\n","from efficientnet_pytorch import EfficientNet\n","from torchvision import transforms\n","from PIL import Image\n","import numpy as np\n","import pandas as pd"],"metadata":{"id":"GFhiYRbKvFsN","executionInfo":{"status":"ok","timestamp":1747625937176,"user_tz":-420,"elapsed":138855,"user":{"displayName":"An Nguyễn","userId":"14264574941995497895"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3571fbc3-999f-4a3e-df81-5139b1e11898"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.1/54.1 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.1/323.1 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["!pip install -q timm\n","import timm"],"metadata":{"id":"oIFAYNImoEyG","executionInfo":{"status":"ok","timestamp":1747626025524,"user_tz":-420,"elapsed":7069,"user":{"displayName":"An Nguyễn","userId":"14264574941995497895"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model, num_heads):\n","        super(MultiHeadAttention, self).__init__()\n","        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n","        self.d_model = d_model\n","        self.num_heads = num_heads\n","        self.d_k = d_model // num_heads\n","\n","        self.W_q = nn.Linear(d_model, d_model)\n","        self.W_k = nn.Linear(d_model, d_model)\n","        self.W_v = nn.Linear(d_model, d_model)\n","        self.W_o = nn.Linear(d_model, d_model)\n","\n","    def forward(self, x):\n","        batch_size, seq_len, d_model = x.size()\n","\n","        Q = self.W_q(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n","        K = self.W_k(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n","        V = self.W_v(x).view(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n","\n","        scores = torch.matmul(Q, K.transpose(-2, -1)) / (self.d_k ** 0.5)\n","        attn = torch.softmax(scores, dim=-1)\n","        context = torch.matmul(attn, V)\n","\n","        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, d_model)\n","        output = self.W_o(context)\n","        return output"],"metadata":{"id":"-xHhnSgv0Nze","executionInfo":{"status":"ok","timestamp":1747625961973,"user_tz":-420,"elapsed":10,"user":{"displayName":"An Nguyễn","userId":"14264574941995497895"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["class CustomEfficientNet(nn.Module):\n","    def __init__(self, num_classes):\n","        super(CustomEfficientNet, self).__init__()\n","        try:\n","            self.base_model = timm.create_model('efficientnet_b0', pretrained=True)\n","            print(\"Tải trọng số pretrained thành công!\")\n","        except Exception as e:\n","            print(f\"Lỗi khi tải trọng số pretrained: {e}\")\n","            self.base_model = timm.create_model('efficientnet_b0', pretrained=False)\n","            print(\"Khởi tạo mô hình với trọng số ngẫu nhiên.\")\n","\n","        self.conv_stem = self.base_model.conv_stem\n","        self.bn1 = self.base_model.bn1\n","        self.blocks = self.base_model.blocks\n","        self.conv_head = self.base_model.conv_head\n","        self.bn2 = self.base_model.bn2\n","        self.global_pool = self.base_model.global_pool\n","\n","        # Lấy số kênh đầu ra từ các khối bằng cách forward một tensor mẫu\n","        self.feature_dims = []\n","        self.feature_sizes = []\n","        with torch.no_grad():\n","            x = torch.randn(1, 3, 224, 224)\n","            x = self.conv_stem(x)\n","            x = self.bn1(x)\n","            for block in self.blocks:\n","                x = block(x)\n","                self.feature_dims.append(x.size(1))  # Số kênh\n","                self.feature_sizes.append(x.size(2))  # Kích thước không gian (H)\n","\n","        # Debug: In số kênh và kích thước không gian\n","        print(\"Số kênh của các khối:\", self.feature_dims)\n","        print(\"Kích thước không gian của các khối:\", self.feature_sizes)\n","\n","        # Tầng convolution để chuẩn hóa đặc trưng (lấy 3 khối cuối)\n","        self.fusion_convs = nn.ModuleList([\n","            nn.Conv2d(dim, 320, kernel_size=1) for dim in self.feature_dims[-3:]\n","        ])\n","\n","        # Tầng pooling để chuẩn hóa kích thước không gian về 7x7\n","        self.spatial_norm = nn.ModuleList([\n","            nn.AdaptiveMaxPool2d(output_size=7) for _ in range(3)\n","        ])\n","\n","        # SE Block cho hợp nhất\n","        self.se_block = nn.Sequential(\n","            nn.AdaptiveAvgPool2d(1),\n","            nn.Conv2d(320 * 3, 320 // 8, kernel_size=1),\n","            nn.ReLU(),\n","            nn.Conv2d(320 // 8, 320 * 3, kernel_size=1),\n","            nn.Sigmoid()\n","        )\n","\n","        # MHA\n","        self.mha = MultiHeadAttention(d_model=320 * 3, num_heads=8)\n","\n","        # Tầng fully connected\n","        self.fc = nn.Linear(320 * 3, num_classes)\n","\n","        # Đóng băng backbone\n","        for name, param in self.base_model.named_parameters():\n","            if \"blocks.5\" not in name:\n","                param.requires_grad = False\n","\n","    def forward(self, x):\n","        x = self.conv_stem(x)\n","        x = self.bn1(x)\n","\n","        # Lấy đặc trưng từ các khối\n","        features = []\n","        for i, block in enumerate(self.blocks):\n","            x = block(x)\n","            if i >= len(self.blocks) - 3:  # Lấy 3 khối cuối\n","                features.append(x)\n","\n","        # Chuẩn hóa kích thước không gian và số kênh\n","        fused_features = []\n","        for feat, conv, norm in zip(features, self.fusion_convs, self.spatial_norm):\n","            feat = norm(feat)  # Chuẩn hóa kích thước không gian về 7x7\n","            feat = conv(feat)  # Chuẩn hóa số kênh về 320\n","            fused_features.append(feat)\n","\n","        fused = torch.cat(fused_features, dim=1)  # [batch_size, 320*3, 7, 7]\n","        se_weights = self.se_block(fused)\n","        fused = fused * se_weights  # Áp dụng SE\n","        fused = self.global_pool(fused).squeeze(-1).squeeze(-1)  # [batch_size, 320*3]\n","\n","        # Áp dụng MHA\n","        fused = fused.unsqueeze(1)  # [batch_size, 1, 320*3]\n","        fused = self.mha(fused)\n","        fused = fused.squeeze(1)  # [batch_size, 320*3]\n","\n","        # Tầng fully connected\n","        x = self.fc(fused)\n","        return x"],"metadata":{"id":"XLAUJ_Km0QQL","executionInfo":{"status":"ok","timestamp":1747625964033,"user_tz":-420,"elapsed":60,"user":{"displayName":"An Nguyễn","userId":"14264574941995497895"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Danh sách lớp COCO 2017 (80 lớp)\n","COCO_CLASSES = [\n","    \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\", \"train\", \"truck\", \"boat\",\n","    \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \"bird\", \"cat\",\n","    \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\",\n","    \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\",\n","    \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n","    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \"apple\",\n","    \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\",\n","    \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\", \"toilet\", \"tv\", \"laptop\",\n","    \"mouse\", \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\",\n","    \"refrigerator\", \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n","]\n","\n","# Biến đổi ảnh đầu vào\n","val_transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","])\n","\n","# Hàm dự đoán ảnh\n","def predict_image(image, model, device, threshold=0.5):\n","    # Chuyển ảnh sang PIL Image nếu là numpy array (từ Gradio)\n","    if isinstance(image, np.ndarray):\n","        image = Image.fromarray(image).convert('RGB')\n","\n","    # Áp dụng biến đổi và chuyển sang tensor\n","    image_tensor = val_transform(image).unsqueeze(0).to(device)\n","\n","    # Dự đoán\n","    model.eval()\n","    with torch.no_grad():\n","        output = model(image_tensor)\n","        probs = torch.sigmoid(output).squeeze().cpu().numpy()\n","\n","    # Nhãn vượt ngưỡng\n","    predicted_labels = [(COCO_CLASSES[i], float(probs[i])) for i in range(len(probs)) if probs[i] > threshold]\n","    predicted_labels = sorted(predicted_labels, key=lambda x: x[1], reverse=True)\n","\n","    # Top-5 nhãn có xác suất cao nhất\n","    top5_indices = np.argsort(probs)[-5:][::-1]\n","    top5_labels = [(COCO_CLASSES[i], float(probs[i])) for i in top5_indices]\n","\n","    return image, predicted_labels, top5_labels\n","\n","# Hàm giao diện Gradio\n","def gradio_predict(image, threshold):\n","    if image is None:\n","        return None, \"Vui lòng tải lên một ảnh!\", None\n","\n","    # Dự đoán\n","    image, predicted_labels, top5_labels = predict_image(image, model, device, threshold)\n","\n","    # Tạo output text cho nhãn vượt ngưỡng\n","    if predicted_labels:\n","        output_text = \"Nhãn dự đoán (xác suất > {}):\\n\".format(threshold)\n","        for label, prob in predicted_labels:\n","            output_text += f\"{label}: {prob:.4f}\\n\"\n","    else:\n","        output_text = f\"Không có nhãn nào được dự đoán với xác suất > {threshold}.\"\n","\n","    # Tạo bảng top-5 nhãn\n","    top5_df = pd.DataFrame(top5_labels, columns=[\"Nhãn\", \"Xác suất\"])\n","\n","    return image, output_text, top5_df\n","\n","# Xác định thiết bị (GPU hoặc CPU)\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Sử dụng thiết bị: {device}\")\n","\n","# Tải mô hình từ checkpoint\n","model = CustomEfficientNet(num_classes=80).to(device)\n","checkpoint_path = \"/content/drive/MyDrive/COCO2017/model_best.pth\"\n","\n","try:\n","    checkpoint = torch.load(checkpoint_path, map_location=device)\n","    if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n","        model.load_state_dict(checkpoint['model_state_dict'])\n","        print(\"Đã tải trạng thái mô hình từ checkpoint (định dạng dictionary)!\")\n","    else:\n","        model.load_state_dict(checkpoint)\n","        print(\"Đã tải trạng thái mô hình từ checkpoint (định dạng state_dict trực tiếp)!\")\n","    model.eval()\n","except Exception as e:\n","    print(f\"Lỗi khi tải mô hình: {e}\")\n","    raise\n","\n","# Tạo giao diện Gradio\n","iface = gr.Interface(\n","    fn=gradio_predict,\n","    inputs=[\n","        gr.Image(type=\"numpy\", label=\"Tải ảnh lên\"),\n","        gr.Slider(minimum=0.1, maximum=0.9, value=0.5, step=0.05, label=\"Ngưỡng xác suất\")\n","    ],\n","    outputs=[\n","        gr.Image(type=\"pil\", label=\"Ảnh đầu vào\"),\n","        gr.Textbox(label=\"Nhãn dự đoán\"),\n","        gr.Dataframe(label=\"Top-5 nhãn có xác suất cao nhất\")\n","    ],\n","    title=\"Ứng dụng gắn nhãn ảnh đa nhãn (COCO 2017)\",\n","    description=\"Tải lên một ảnh để gắn nhãn từ 80 lớp COCO 2017. Điều chỉnh ngưỡng xác suất để kiểm soát số lượng nhãn. Top-5 nhãn có xác suất cao nhất được hiển thị để hỗ trợ kiểm tra.\"\n",")\n","\n","# Chạy giao diện\n","iface.launch(share=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":704},"id":"Ga-uwldA0Dtr","executionInfo":{"status":"ok","timestamp":1747626084032,"user_tz":-420,"elapsed":7749,"user":{"displayName":"An Nguyễn","userId":"14264574941995497895"}},"outputId":"6d03786a-b007-49bc-cb6d-0e4346af1b14"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Sử dụng thiết bị: cpu\n","Tải trọng số pretrained thành công!\n","Số kênh của các khối: [16, 24, 40, 80, 112, 192, 320]\n","Kích thước không gian của các khối: [112, 56, 28, 14, 14, 7, 7]\n","Đã tải trạng thái mô hình từ checkpoint (định dạng state_dict trực tiếp)!\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://92b13a682831952d75.gradio.live\n","\n","This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://92b13a682831952d75.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":8}]}]}