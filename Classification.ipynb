{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "725fc2da-6bfe-4e06-8495-c789b8829b01"
      },
      "source": [
        "# Bài tập\n",
        "Dùng keras để xây dựng mô hình deep learning để nhận dạng logo của các hãng xe.<br>\n",
        "Có 8 loại logo cần nhận dạng như sau:<br>\n",
        "<img src=\"logo_classes.png\" alt=\"Classes\" style=\"width:224px; heoght:224px\"/><br>\n",
        "Ảnh ví dụ để test mô hình, kích thước của ảnh test sẽ được scale về <strong>224x224</strong>:<br>\n",
        "<img src=\"Lexus.jpg\" alt=\"Lexus\" style=\"width:224px; heoght:224px\"/><br>"
      ],
      "id": "725fc2da-6bfe-4e06-8495-c789b8829b01"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcoS3KCWkQl5",
        "outputId": "9537a3e5-23cb-4ce6-bfb2-70376e4666b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "mcoS3KCWkQl5"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XYAFdFo4h42z"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications import ResNet50, VGG19, VGG16, ResNet101V2\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report, accuracy_score\n",
        "from tensorflow.keras.layers import Conv2D, Dropout, Dense, Flatten, MaxPooling2D, GlobalAveragePooling2D, Activation, BatchNormalization, MaxPooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2"
      ],
      "id": "XYAFdFo4h42z"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ybmZKroqpy8g"
      },
      "outputs": [],
      "source": [
        "def load_images(folder, class_map):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for brand, index in class_map.items():\n",
        "        brand_path = os.path.join(folder, brand)\n",
        "        if os.path.isdir(brand_path):\n",
        "            for img_file in os.listdir(brand_path):\n",
        "                img_path = os.path.join(brand_path, img_file)\n",
        "                img = cv2.imread(img_path)\n",
        "                img = cv2.resize(img, (224, 224))\n",
        "                img = img / 255.0\n",
        "                images.append(img)\n",
        "                labels.append(index)\n",
        "    return np.array(images), np.array(labels)"
      ],
      "id": "ybmZKroqpy8g"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2peC0g8Gpy-6"
      },
      "outputs": [],
      "source": [
        "class_map = {brand: idx for idx, brand in enumerate(os.listdir(\"/content/drive/MyDrive/DeepLearning/Train\"))}"
      ],
      "id": "2peC0g8Gpy-6"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "k-mk_klLpzBQ"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = load_images(\"/content/drive/MyDrive/DeepLearning/Train\", class_map)\n",
        "X_test, y_test = load_images(\"/content/drive/MyDrive/DeepLearning/Test\", class_map)"
      ],
      "id": "k-mk_klLpzBQ"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "m_fqvQJ7pzDw"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(y_train, 8)\n",
        "y_test = to_categorical(y_test, 8)"
      ],
      "id": "m_fqvQJ7pzDw"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWZBExiVpzGY",
        "outputId": "86830fb7-42ac-4b15-b749-a00d30736ac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2013 images belonging to 8 classes.\n",
            "Found 500 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.95,\n",
        "    zoom_range=0.95,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/DeepLearning/Train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset=\"training\")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/DeepLearning/Train',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset=\"validation\")"
      ],
      "id": "NWZBExiVpzGY"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOuDTZ9hpzIo",
        "outputId": "8364ab42-0dde-4130-a02d-84316a6fc236"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m171317808/171317808\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = ResNet101V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "for layer in base_model.layers[:-50]:\n",
        "    layer.trainable = False\n",
        "\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.6)(x)\n",
        "out = Dense(8, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=out)\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "id": "HOuDTZ9hpzIo"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BMgi_n2pzK7",
        "outputId": "02a5e1b0-cc28-4730-9cce-d3a121310600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873ms/step - accuracy: 0.3940 - loss: 9.4069\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15800, saving model to best_model_cnn.keras\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 1s/step - accuracy: 0.3954 - loss: 9.3870 - val_accuracy: 0.1580 - val_loss: 255.3788\n",
            "Epoch 2/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647ms/step - accuracy: 0.6356 - loss: 5.6263\n",
            "Epoch 2: val_accuracy improved from 0.15800 to 0.39600, saving model to best_model_cnn.keras\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 922ms/step - accuracy: 0.6361 - loss: 5.6176 - val_accuracy: 0.3960 - val_loss: 14.2152\n",
            "Epoch 3/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 626ms/step - accuracy: 0.7332 - loss: 3.7081\n",
            "Epoch 3: val_accuracy improved from 0.39600 to 0.72000, saving model to best_model_cnn.keras\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 995ms/step - accuracy: 0.7331 - loss: 3.7035 - val_accuracy: 0.7200 - val_loss: 3.4244\n",
            "Epoch 4/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640ms/step - accuracy: 0.7516 - loss: 2.6498\n",
            "Epoch 4: val_accuracy improved from 0.72000 to 0.78600, saving model to best_model_cnn.keras\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 876ms/step - accuracy: 0.7516 - loss: 2.6473 - val_accuracy: 0.7860 - val_loss: 2.1981\n",
            "Epoch 5/5\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640ms/step - accuracy: 0.7804 - loss: 2.0051\n",
            "Epoch 5: val_accuracy did not improve from 0.78600\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 836ms/step - accuracy: 0.7804 - loss: 2.0037 - val_accuracy: 0.7260 - val_loss: 5.6713\n"
          ]
        }
      ],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.001, patience=15, restore_best_weights=True)\n",
        "checkpoint = ModelCheckpoint(\"best_model_cnn.keras\", monitor='val_accuracy', save_best_only=True, verbose=1)\n",
        "history = model.fit(\n",
        "        train_generator,\n",
        "        epochs=5,\n",
        "        validation_data=validation_generator,\n",
        "        batch_size = 64,\n",
        "        callbacks = [early_stopping, checkpoint])"
      ],
      "id": "8BMgi_n2pzK7"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5J2V03WdpzNI",
        "outputId": "35a07314-8d1b-468b-9538-e51171cb2ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/DeepLearning/Test\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False\n",
        ")"
      ],
      "id": "5J2V03WdpzNI"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pC-dVQO4r83f",
        "outputId": "0052a778-80f9-492c-cc32-01c4d7dfdc72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.8455 - loss: 2.7469\n",
            "Test Accuracy: 0.8375\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(test_data)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")"
      ],
      "id": "pC-dVQO4r83f"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}